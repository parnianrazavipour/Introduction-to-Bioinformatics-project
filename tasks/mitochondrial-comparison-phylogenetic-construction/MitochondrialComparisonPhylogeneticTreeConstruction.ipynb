{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project of Introduction to Bioinformatics\n",
    "\n",
    "## Comparative Mitochondrial Genomics and Phylogenetic Analysis\n",
    "\n",
    "#### TA: Javad Razi (j.razi@outlook.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task focuses on the comparative analysis of mitochondrial genomes from different species, primarily birds, mammals, and insects. The aim is to understand the evolutionary relationships between these species by analyzing and comparing their mitochondrial DNA, which is about 16,000 base pairs in length. You will use advanced computational methods to construct phylogenetic trees and delve into the ecological and anthropological insights that can be gleaned from this data. This project is designed to provide a comprehensive understanding of mitochondrial genomics, its importance in evolutionary biology, and its applications in broader scientific contexts.\n",
    "\n",
    "You will learn:\n",
    "\n",
    "- Techniques for aligning and comparing mitochondrial DNA sequences.\n",
    "- How to construct and interpret phylogenetic trees using advanced computational methods.\n",
    "- The application of mitochondrial genomics in understanding ecological interactions and human evolutionary history.\n",
    "\n",
    "#### Task Roadmap\n",
    "\n",
    "1. **Mitochondrial Genome Comparison**:\n",
    "   - Align mitochondrial DNA sequences from the provided dataset.\n",
    "   - Analyze these sequences to identify similarities and differences across species.\n",
    "\n",
    "2. **Phylogenetic Analysis Using Advanced Methods**:\n",
    "   - Apply Maximum Likelihood (ML) and Bayesian Inference methods, utilizing tools like `ETE Toolkit`, `DendroPy`, `BEAST`, or `PyRate`.\n",
    "   - Compare the trees generated by these methods to understand how different approaches can lead to different interpretations of the data.\n",
    "\n",
    "3. **Cross-Disciplinary Applications (Bonus)**:\n",
    "   - **Ecology**: Examine how mitochondrial DNA analysis can reveal information about species adaptation, migration, and conservation. This involves understanding how genetic variation within and between species can inform ecological strategies and conservation efforts.\n",
    "   - **Anthropology**: Investigate the use of mitochondrial DNA in tracing human evolution and migration patterns. This includes studying the mitochondrial DNA of mammals in your dataset to draw parallels with human evolutionary studies.\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "The mitochondrial DNA data for birds, mammals, and insects will be provided to you. This dataset has been curated to facilitate a comprehensive comparative analysis and is essential for the completion of your phylogenetic studies.\n",
    "\n",
    "### Useful Resources and Material\n",
    "\n",
    "- [Mitochondrial DNA - Wikipedia](https://en.wikipedia.org/wiki/Mitochondrial_DNA): A general introduction to the structure, function, origin, and diversity of mitochondrial DNA, as well as its applications in various fields such as medicine, forensics, and anthropology.\n",
    "- [Mitochondrial DNA Analysis: Introduction, Methods, and Applications](https://bioinfo.cd-genomics.com/mitochondrial-dna-analysis-introduction-methods-and-applications.html): An explanation of the basics of mitochondrial DNA sequencing, bioinformatics analysis, heteroplasmy, and advantages of mitochondrial DNA analysis over nuclear DNA analysis.\n",
    "- [Phylogenetic Tree- Definition, Types, Steps, Methods, Uses - Microbe Notes](https://microbenotes.com/phylogenetic-tree/): A coverage of the concepts and methods of phylogenetic tree construction, including the types of phylogenetic trees, the steps involved in phylogenetic analysis, the main methods of phylogenetic inference, and the applications of phylogenetic trees in various disciplines.\n",
    "- [Phylogenetics - Wikipedia](https://en.wikipedia.org/wiki/Phylogenetics): An overview of the field of phylogenetics, which is the study of the evolutionary history and relationships among or within groups of organisms. It also discusses the data sources, models, algorithms, software, and challenges of phylogenetic analysis.\n",
    "- [ETE Toolkit](http://etetoolkit.org/): A Python library for manipulating, analyzing, and visualizing phylogenetic trees. It supports various formats, methods, and tools for phylogenetic analysis, such as alignment, tree inference, tree comparison, tree annotation, and tree visualization.\n",
    "- [DendroPy](https://dendropy.org/): Another Python library for phylogenetic computing. It provides a comprehensive API for working with phylogenetic data structures, such as trees, characters, and networks. It also offers a rich set of functions for simulation, manipulation, analysis, and annotation of phylogenetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration and Reflection\n",
    "\n",
    "As we proceed with our analysis of mitochondrial DNA for phylogenetic tree construction, it is valuable to contemplate a few questions. These inquiries aim to facilitate a more thorough understanding of the roles and characteristics of mitochondrial DNA in the context of evolutionary biology:\n",
    "\n",
    "1. **Maternal Inheritance and Its Implications**: How does the maternal inheritance of mitochondrial DNA simplify our understanding of evolutionary lineage compared to nuclear DNA, which undergoes recombination? What unique insights can this aspect provide in tracing the evolutionary history of species?\n",
    "\n",
    "2. **Mutation Rate and Evolutionary Insights**: Mitochondrial DNA mutates at a faster rate than nuclear DNA. How does this characteristic make mtDNA a more sensitive tool for detecting recent evolutionary events and relationships among closely related species? Can you think of any specific scenarios or studies where this property of mtDNA has been particularly instrumental?\n",
    "\n",
    "Reflect on these questions as you work through the project, and consider how the properties of mitochondrial DNA enhance its value and applicability in evolutionary biology and beyond. Provide your answer either in this notebook, or in your report (if you had one).\n",
    "\n",
    "<blockquote style=\"font-family:Arial; color:red; font-size:16px; border-left:0px solid red; padding: 10px;\">\n",
    "    <strong>Don't forget to answer these questions!</strong>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Installing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biopython (1.81) is installed\n",
      "pandas (2.0.3) is installed\n",
      "numpy (1.24.3) is installed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'biopython',\n",
    "    'pandas',\n",
    "    'numpy'\n",
    "]\n",
    "\n",
    "for package in REQUIRED_PACKAGES:\n",
    "    try:\n",
    "        dist = pkg_resources.get_distribution(package)\n",
    "        print('{} ({}) is installed'.format(dist.key, dist.version))\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print('{} is NOT installed'.format(package))\n",
    "        install(package)\n",
    "        print('{} was successfully installed.'.format(package))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Dataset Expansion\n",
    "\n",
    "Our first task is to augment our dataset with additional species. This involves engaging with the NCBI database to retrieve mitochondrial DNA sequences.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- **Species Selection**: Identify and choose 10 additional species to include in your dataset. Aim for a diverse selection to enrich your phylogenetic analysis.\n",
    "\n",
    "- **Querying NCBI Database**: Use the NCBI database to locate mitochondrial DNA sequences for your chosen species. While you can manually search on the [NCBI website](https://www.ncbi.nlm.nih.gov/), consider automating this process through their API for a more efficient approach.\n",
    "    - **Example Query**: As a starting point, you might use a query like `\"mitochondrion[Filter] AND (your_species_name[Organism])` to find specific mtDNA sequences. Adjust the query parameters according to your species selection.\n",
    "    - **Documentation**: Familiarize yourself with the [NCBI API documentation](https://www.ncbi.nlm.nih.gov/books/NBK25497/) for detailed guidance on constructing queries.\n",
    "\n",
    "- **Using NCBI Website**: You are welcome to use the NCBI website for this task. If you do so, document each step of your process clearly in your task report. This should include the species names, search terms used, and how you determined the relevant sequences to include.\n",
    "\n",
    "- **Bonus Opportunity**: Implementing an automated, methodological approach using the NCBI API and relevant Python packages to add all 10 records in your dataset will earn you a 50% bonus for this section. Your method should be structured and replicable, demonstrating a systematic approach to data collection.\n",
    "\n",
    "Remember, the goal is to methodically expand your dataset with relevant mtDNA sequences, paving the way for insightful phylogenetic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   taxo_id                 specie blast_name genbank_common_name  \\\n",
      "0     8945  Eudynamys scolopaceus      birds          Asian koel   \n",
      "1     7460         Apis mellifera       Bees           honey bee   \n",
      "2    36300      Pelecanus crispus      birds   Dalmatian pelican   \n",
      "3    10116      Rattus norvegicus    Rodents          Norway rat   \n",
      "4     9031          Gallus gallus      birds       Gallus gallus   \n",
      "\n",
      "  accession_number                                              mtDNA  \n",
      "0        NC_060520  https://www.ncbi.nlm.nih.gov/nucleotide/NC_060...  \n",
      "1        NC_051932  https://www.ncbi.nlm.nih.gov/nucleotide/NC_051...  \n",
      "2         OR620163    https://www.ncbi.nlm.nih.gov/nuccore/OR620163.1  \n",
      "3        NC_001665     https://www.ncbi.nlm.nih.gov/nuccore/NC_001665  \n",
      "4        NC_006088   https://www.ncbi.nlm.nih.gov/nuccore/NC_053523.1  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./dataset/species.csv')\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 10 more species to your dataset\n",
    "# for species in additional_species:\n",
    "    # Fetch mtDNA and add to the dataset\n",
    "\n",
    "# List of 10 additional species to add\n",
    "additional_species = [\n",
    "    'Pan troglodytes',  # Chimpanzee, a close relative to humans, offering insights into human evolution.\n",
    "    'Canis lupus',      # Gray wolf, representing carnivorous mammals and their evolutionary dynamics.\n",
    "    'Felis catus',      # Domestic cat, a common pet with a well-documented mitochondrial genome.\n",
    "    'Apteryx australis',# Kiwi bird, a unique bird species with distinct evolutionary traits.\n",
    "    'Gallus gallus',    # Chicken, a domesticated bird with significant agricultural importance.\n",
    "    'Apis mellifera',   # Western honey bee, an insect with crucial ecological roles.\n",
    "    'Drosophila melanogaster', # Fruit fly, a model organism in genetic research.\n",
    "    'Elephas maximus',  # Asian elephant, a large mammal with conservation interest.\n",
    "    'Orcinus orca',     # Killer whale, a marine mammal with complex social structures.\n",
    "    'Ursus maritimus',  # Polar bear, an apex predator in Arctic regions, facing climate change threats.\n",
    "]\n",
    "Entrez.email = \"ahmadreza1380.hamzei@gmail.com\"\n",
    "\n",
    "# Function to fetch mtDNA sequence ID for a species\n",
    "def fetch_species_details(species_name):\n",
    "    \"\"\"\n",
    "    Fetches details for a given species by querying NCBI's database.\n",
    "    Returns a dictionary with the required information.\n",
    "    \"\"\"\n",
    "    search_term = f\"{species_name}[Organism] AND mitochondrion[Filter]\"\n",
    "    handle = Entrez.esearch(db=\"nucleotide\", term=search_term, retmax=1)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    \n",
    "    if record['IdList']:\n",
    "        accession_id = record['IdList'][0]\n",
    "        # Fetch detailed record for the accession number\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=accession_id, rettype=\"gb\", retmode=\"xml\")\n",
    "        records = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        details = {}\n",
    "        # Extracting details from the fetched record\n",
    "        # Note: This is a simplified example. You might need to adjust parsing based on actual record structure\n",
    "        for record in records[0]['GBSeq_feature-table']:\n",
    "            if record['GBFeature_key'] == 'source':\n",
    "                for qualifier in record['GBFeature_quals']:\n",
    "                    if qualifier['GBQualifier_name'] == 'db_xref':\n",
    "                        # Extracting taxo_id\n",
    "                        taxo_id = qualifier['GBQualifier_value'].split(\":\")[1]\n",
    "                        details['taxo_id'] = taxo_id\n",
    "                    if qualifier['GBQualifier_name'] == 'organism':\n",
    "                        # Extracting species name\n",
    "                        details['specie'] = qualifier['GBQualifier_value']\n",
    "                        # Assuming genbank_common_name is the same as species name\n",
    "                        details['genbank_common_name'] = qualifier['GBQualifier_value']\n",
    "        taxonomy = records[0]['GBSeq_taxonomy'].split('; ')\n",
    "        if taxonomy:\n",
    "            # This is a simplistic approach; you might need a more sophisticated method to infer the blast name\n",
    "            details['blast_name'] = taxonomy[-1]  # Using the highest taxonomic classification as a placeholder\n",
    "        # Accession number and mtDNA URL construction\n",
    "        details['accession_number'] = records[0]['GBSeq_primary-accession']\n",
    "        details['mtDNA'] = f\"https://www.ncbi.nlm.nih.gov/nuccore/{records[0]['GBSeq_accession-version']}\"\n",
    "\n",
    "        return details\n",
    "\n",
    "# Save the expanded dataset\n",
    "# dataset.to_csv('./dataset/expanded_dataset.csv', index=False)\n",
    "\n",
    "# Initialize your dataset\n",
    "new_rows = []\n",
    "\n",
    "# Iterate over the list of additional species\n",
    "for species in additional_species:\n",
    "    details = fetch_species_details(species)\n",
    "    if details:\n",
    "        new_rows.append(details)\n",
    "\n",
    "new_species_df = pd.DataFrame(new_rows)\n",
    "expanded_dataset = pd.concat([dataset, new_species_df], ignore_index=True)\n",
    "\n",
    "# Save the expanded dataset\n",
    "expanded_dataset.to_csv('./dataset/expanded_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sequence Download and Preparation\n",
    "\n",
    "The next step in our project involves downloading the mitochondrial DNA sequences for each species and preparing them for analysis.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- **Download mtDNA Sequences**: Write a script to download the mtDNA sequences from the links provided in your dataset. The sequences should be in FASTA format, which is the standard for nucleotide sequences.\n",
    "\n",
    "- **Sequence Labeling**: Properly label each sequence within the FASTA file. This header, starting with '>', should include the species name and any other relevant information (e.g., `>Eudynamys_scolopaceus_NC_060520`). This is crucial for identifying the sequences in subsequent analysis.\n",
    "\n",
    "- **Concatenate Sequences**:\n",
    "    - Create a script to concatenate all downloaded sequences into a single `.fasta` or `.fna` file. \n",
    "    - Ensure each sequence in the file is clearly separated by its header line, which is important for differentiating the sequences of various species.\n",
    "\n",
    "#### Tips for Writing the Download and Concatenation Script:\n",
    "- Use Python libraries such as `httpx` or `requests`, or any other tool you prefer for downloading sequences. For processing FASTA files you can use a wide range of tools. One recommended option is `Biopython` library.\n",
    "- Use a loop to go through each link in the dataset, download the sequence, and append it to your concatenated file.\n",
    "- Maintain the format integrity of the FASTA file, ensuring each sequence is correctly associated with its header.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: Eudynamys_scolopaceus_NC_060520\n",
      "Name: <unknown name>\n",
      "Number of features: 0\n",
      "Seq('GTCCTCGTAGCTTAAACAAAGCATGACGCTGAAGATGTCAAGATGGCCCACCAC...AAC')\n",
      "Downloaded and saved ./fasta/Eudynamys_scolopaceus_NC_060520.fasta\n",
      "ID: Apis_mellifera_NC_051932\n",
      "Name: <unknown name>\n",
      "Number of features: 0\n",
      "Seq('ATTTATATAGTTTAAAAAAAACATTATATTTTCAATATAAAAATAATTAAATTT...ATT')\n",
      "Downloaded and saved ./fasta/Apis_mellifera_NC_051932.fasta\n",
      "ID: Pelecanus_crispus_OR620163\n",
      "Name: <unknown name>\n",
      "Number of features: 0\n",
      "Seq('GGCACACCCATAATAGTAGCCCAAGACACCTTGCTTAGCCACACCCTCACGGGT...CCA')\n",
      "Downloaded and saved ./fasta/Pelecanus_crispus_OR620163.fasta\n",
      "ID: Rattus_norvegicus_NC_001665\n",
      "Name: <unknown name>\n",
      "Number of features: 0\n",
      "Seq('GTTAATGTAGCTTATAATAAAGCAAAGCACTGAAAATGCTTAGATGGATTCAAA...AAA')\n",
      "Downloaded and saved ./fasta/Rattus_norvegicus_NC_001665.fasta\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     42\u001b[0m     species_name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecie\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mdownload_mtDNA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccession_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Concatenate sequences into a single FASTA file\u001b[39;00m\n\u001b[1;32m     46\u001b[0m output_concatenated_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./concatenated_sequences.fasta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m, in \u001b[0;36mdownload_mtDNA\u001b[0;34m(accession_id, species_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Fetch the sequence using Entrez\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mefetch(db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnucleotide\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39maccession_id, rettype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m\"\u001b[39m, retmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     sequence_data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     handle\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Remove extra '>' characters and format the header line correctly\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readall_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:573\u001b[0m, in \u001b[0;36mHTTPResponse._readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:556\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:516\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1270\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1269\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1128\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Write a function to download mtDNA sequences\n",
    "import os\n",
    "output_directory = \"./fasta\"\n",
    "\n",
    "def download_mtDNA(accession_id, species_name):\n",
    "    \"\"\"\n",
    "    Download mtDNA sequence using Entrez and save it in a labeled FASTA file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the sequence using Entrez\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=accession_id, rettype=\"fasta\", retmode=\"text\")\n",
    "        sequence_data = handle.read()\n",
    "        handle.close()\n",
    "\n",
    "        # Remove extra '>' characters and format the header line correctly\n",
    "        sequence_lines = sequence_data.split('\\n')\n",
    "        formatted_sequence_data = \"\\n\".join([*sequence_lines[1:]])\n",
    "        \n",
    "        # Create a SeqRecord object\n",
    "        formatted_sequence_data = formatted_sequence_data.replace('\\n', '')\n",
    "        seq_record = SeqRecord(Seq(formatted_sequence_data), id=f\"{species_name}_{accession_id}\", description=\"\")\n",
    "\n",
    "        # Save the sequence in a labeled FASTA file\n",
    "        output_filename = os.path.join(output_directory, f\"{species_name}_{accession_id}.fasta\")\n",
    "        with open(output_filename, \"w\") as output_handle:\n",
    "            print(seq_record)\n",
    "            SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "\n",
    "        print(f\"Downloaded and saved {output_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download sequence for {species_name} ({accession_id}): {str(e)}\")\n",
    "\n",
    "# Loop through the dataset and download each mtDNA sequence\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "## Load dataset\n",
    "dataset = pd.read_csv('./dataset/expanded_dataset.csv')\n",
    "\n",
    "# List to hold downloaded sequences\n",
    "# Loop through the dataset and download/save each mtDNA sequence\n",
    "for index, row in dataset.iterrows():\n",
    "    species_name = row['specie'].replace(' ', '_')\n",
    "    download_mtDNA(row['accession_number'], species_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated sequences saved as ./concatenated_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "# Concatenate sequences into a single FASTA file\n",
    "output_concatenated_filename = \"./concatenated_sequences.fasta\"\n",
    "with open(output_concatenated_filename, \"w\") as concatenated_handle:\n",
    "    for filename in os.listdir(output_directory):\n",
    "        if filename.endswith(\".fasta\"):\n",
    "            file_path = os.path.join(output_directory, filename)\n",
    "            with open(file_path, \"r\") as individual_handle:\n",
    "                concatenated_handle.write(individual_handle.read())\n",
    "\n",
    "print(f\"Concatenated sequences saved as {output_concatenated_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Sequence Alignment\n",
    "\n",
    "After downloading the mitochondrial DNA sequences, the next critical step is their alignment. This process allows us to compare the sequences and discern the evolutionary relationships among the species.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- **Select an Alignment Tool**: Choose one of the following alignment tools based on your project needs. Each tool has its strengths and is widely used in bioinformatics for multiple sequence alignment.\n",
    "\n",
    "1. **MAFFT**:\n",
    "    - **Brief Introduction**: MAFFT (Multiple Alignment using Fast Fourier Transform) is renowned for its speed and efficiency, particularly suitable for large datasets.\n",
    "    - **Resources**:\n",
    "        - [MAFFT Official Documentation](https://mafft.cbrc.jp/alignment/software/)\n",
    "        - [Example Usage on GitHub](https://github.com/MountainMan12/SARS-Cov2-phylo)\n",
    "        - [Relevant Notebook](https://colab.research.google.com/github/pb3lab/ibm3202/blob/master/tutorials/lab03_phylo.ipynb)\n",
    "\n",
    "2. **Clustal Omega**:\n",
    "    - **Brief Introduction**: Clustal Omega offers high-quality alignments and is user-friendly, ideal for those new to sequence alignment.\n",
    "    - **Resources**:\n",
    "        - [A Python wrapper around Clustal Omega](https://github.com/benchling/clustalo-python)\n",
    "        - [Clustal Omega Official Website](http://www.clustal.org/omega/)\n",
    "\n",
    "3. **MUSCLE**:\n",
    "    - **Brief Introduction**: MUSCLE (Multiple Sequence Comparison by Log-Expectation) is known for its balance between speed and accuracy, making it a versatile choice for various datasets.\n",
    "    - **Resources**:\n",
    "        - [MUSCLE Documentation](https://drive5.com/muscle5/manual/)\n",
    "\n",
    "- **Perform Sequence Alignment**: Utilize your chosen tool to align the downloaded mtDNA sequences. This alignment is foundational for the accurate construction of phylogenetic trees.\n",
    "\n",
    "- **Save Aligned Sequences**: After alignment, save the output in an appropriate format for further analysis in the subsequent steps of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment failed.\n"
     ]
    }
   ],
   "source": [
    "# Install and import the alignment tool\n",
    "# sudo apt-get install mafft\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "\n",
    "# Perform the sequence alignment\n",
    "def perform_alignment(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Perform multiple sequence alignment using MAFFT.\n",
    "    \n",
    "    :param input_file: Path to the input FASTA file containing sequences to align.\n",
    "    :param output_file: Path to the output file to save the aligned sequences.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a MAFFT command line object\n",
    "        mafft_cline = MafftCommandline(input=input_file)\n",
    "\n",
    "        # Run MAFFT alignment\n",
    "        stdout, stderr = mafft_cline()\n",
    "\n",
    "        # Check if the alignment was successful\n",
    "        if not stderr:\n",
    "            # Write the result into output file\n",
    "            with open(output_file, \"w\") as handle:\n",
    "                handle.write(stdout)\n",
    "            print(f\"Alignment completed. Aligned sequences saved in {output_file}\")\n",
    "        else:\n",
    "            print(\"Alignment failed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during alignment: {str(e)}\")\n",
    "\n",
    "# Align your downloaded sequences\n",
    "# perform_alignment('path_to_downloaded_sequences.fasta', 'aligned_sequences.fasta')\n",
    "# Define input and output file paths\n",
    "input_file = './concatenated_sequences.fasta'  # Replace with your input file path\n",
    "output_file = './aligned_sequences.fasta'  # Replace with your desired output file path\n",
    "\n",
    "# Perform the sequence alignment\n",
    "perform_alignment(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Phylogenetic Tree Construction\n",
    "\n",
    "The next phase in our project involves constructing phylogenetic trees to visualize and analyze the evolutionary relationships among the species. We will use three distinct methods, each providing unique insights.\n",
    "\n",
    "#### Phylogenetic Tree Construction Methods:\n",
    "\n",
    "1. **Bayesian Inference Trees**:\n",
    "    - **Overview**: This method uses Bayesian statistics to estimate the likelihood of different evolutionary histories. It's particularly useful for its ability to estimate branch lengths and support values.\n",
    "    - **Tools**: MrBayes, BEAST\n",
    "        - MrBayes ([Official Website](https://nbisweden.github.io/MrBayes/manual.html/)) is widely recognized for its robustness in Bayesian inference.\n",
    "        - BEAST2 ([BEAST Software](https://www.beast2.org/)) is another powerful tool, offering advanced features for complex evolutionary models.\n",
    "\n",
    "2. **Maximum Likelihood Trees**:\n",
    "    - **Overview**: Maximum Likelihood methods evaluate tree topologies based on the likelihood of observed data given a tree model. It's known for its statistical rigor and accuracy.\n",
    "    - **Tools**: RAxML, PhyML\n",
    "        - RAxML ([RAxML GitHub](https://github.com/stamatak/standard-RAxML)) is preferred for large datasets due to its efficiency.\n",
    "        - PhyML ([PhyML Documentation](http://www.atgc-montpellier.fr/phyml/)) offers a balance of speed and accuracy, with a user-friendly interface.\n",
    "\n",
    "3. **Neighbor-Joining Trees**:\n",
    "    - **Overview**: The Neighbor-Joining method is a distance-based approach that constructs phylogenetic trees by evaluating the genetic distance between sequences. It is known for its speed and simplicity, making it well-suited for initial exploratory analyses.\n",
    "    - **Tools**: \n",
    "        - MEGA: A versatile tool specifically used here for constructing Neighbor-Joining trees. It's recognized for its ease of use and effectiveness in phylogenetic analysis. [MEGA Software](https://www.megasoftware.net/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for tree construction\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
    "\n",
    "# Construct a phylogenetic tree using the Neighbor Joining method\n",
    "def construct_tree_NJ(aligned_sequences, output_file):\n",
    "    \"\"\"\n",
    "    Construct a phylogenetic tree using the Neighbor Joining (NJ) method.\n",
    "\n",
    "    :param aligned_sequences: Path to the input aligned sequences in FASTA format.\n",
    "    :param output_file: Path to save the constructed NJ tree.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate the distance matrix\n",
    "        calculator = DistanceCalculator('identity')\n",
    "        dm = calculator.get_distance(aligned_sequences)\n",
    "\n",
    "        # Construct the NJ tree\n",
    "        constructor = DistanceTreeConstructor()\n",
    "        tree = constructor.nj(dm)\n",
    "\n",
    "        print(f\"NJ Tree constructed and saved in {output_file}\")\n",
    "        return tree\n",
    "    except Exception as e:\n",
    "        print(f\"Error during NJ tree construction: {str(e)}\")\n",
    "\n",
    "# Repeat the process for Maximum Likelihood and Supertree methods\n",
    "def construct_tree_ML(aligned_sequences, output_file):\n",
    "    \"\"\"\n",
    "    Construct a Maximum Likelihood (ML) phylogenetic tree using RAxML.\n",
    "\n",
    "    :param input_alignment: Path to the input aligned sequences in FASTA format.\n",
    "    :param output_tree: Path to save the constructed ML tree.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define the RAxML command\n",
    "        raxml_cmd = f\"raxmlHPC-PTHREADS-AVX2 -T 4 -f a -x 12345 -p 12345 -N 100 -m GTRGAMMA -s {aligned_sequences} -n ML_tree\"\n",
    "\n",
    "        # Execute the RAxML command\n",
    "        subprocess.run(raxml_cmd, shell=True, check=True)\n",
    "\n",
    "        # Rename the output tree file to the desired name\n",
    "        subprocess.run(f\"mv RAxML_bestTree.ML_tree {output_file}\", shell=True, check=True)\n",
    "\n",
    "        print(f\"ML Tree constructed and saved in {output_file}\")\n",
    "        return\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during ML tree construction: {e}\")\n",
    "\n",
    "# TODO: \n",
    "# def construct_tree_BI(gene_trees):\n",
    "    # Implement the construction of a tree using bayes inference\n",
    "\n",
    "# TODO: Visualize and save the constructed trees\n",
    "# ml_tree = Phylo.read(ml_tree_output_file, \"newick\")\n",
    "# Phylo.draw(tree, do_show=False)\n",
    "# Phylo.write(tree, 'tree_output.xml', 'phyloxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: In-Depth Phylogenetic Tree Visualization\n",
    "\n",
    "Having constructed phylogenetic trees using different methods, our next task is to visualize these trees effectively. This step is crucial for interpreting the results and communicating our findings.\n",
    "\n",
    "#### Visualization Tools:\n",
    "\n",
    "1. **FigTree**:\n",
    "    - **Overview**: FigTree is designed for the graphical representation of phylogenetic trees. It's excellent for creating publication-ready visualizations.\n",
    "    - **Resource**: [FigTree Tool](http://tree.bio.ed.ac.uk/software/figtree/)\n",
    "    - **Usage**: Use FigTree to add detailed annotations, adjust branch colors, and format tree layouts for clear, interpretable visualizations.\n",
    "\n",
    "2. **iTOL (Interactive Tree Of Life)**:\n",
    "    - **Overview**: iTOL is a web-based tool for the display, annotation, and management of phylogenetic trees, offering extensive customization options.\n",
    "    - **Resource**: [iTOL Website](https://itol.embl.de/)\n",
    "    - **Usage**: Ideal for interactive tree visualizations. It allows users to explore different layers of data through their tree, such as adding charts or color-coding branches.\n",
    "\n",
    "3. **Dendroscope**:\n",
    "    - **Overview**: Dendroscope is a software program for viewing and editing phylogenetic trees, particularly useful for large datasets.\n",
    "    - **Resource**: [Dendroscope Download](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/algorithms-in-bioinformatics/software/dendroscope/)\n",
    "    - **Usage**: Utilize Dendroscope when dealing with large and complex trees or when you need to compare multiple trees side-by-side.\n",
    "\n",
    "#### Task:\n",
    "\n",
    "- **Visualize Each Tree**: Use one or more of the above tools to visualize the phylogenetic trees you constructed using Bayesian inference, maximum likelihood, and neighbor-joining methods.\n",
    "- **Highlight Differences**: Focus on highlighting the differences and similarities between the trees obtained from the different methods. Pay attention to tree topology, branch lengths, and any notable patterns.\n",
    "- **Interpretation and Presentation**: Aim for visualizations that are not only accurate but also interpretable and visually appealing. This will enhance the clarity of your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ####\n",
    "# You code for visualization of each tree\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Disciplinary Applications (Optional)\n",
    "\n",
    "This is an optional part with bonus, relative to the depth of your analysis. Refer to the first part of this notebook. You have complete freedom to do this part anyway you like, but to gain a portion of the bonus score for this section, a bare minimum effort is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Reflective Insights\n",
    "\n",
    "As we conclude our exploration of phylogenetic tree construction and analysis, let's reflect on the insights learned from this task and consider questions that emerge from our findings.\n",
    "\n",
    "#### Interpretation of Results:\n",
    "\n",
    "- Reflect on the phylogenetic trees produced by each method (Bayesian inference, maximum likelihood, and neighbor-joining). Consider how the differences in tree topology might offer varied perspectives on the evolutionary relationships among the species.\n",
    "\n",
    "#### Questions to Ponder:\n",
    "\n",
    "1. **Species Divergence**: Based on the trees, which species appear to have the most ancient divergence? How might this information contribute to our understanding of their evolutionary history?\n",
    "   \n",
    "2. **Common Ancestors**: Are there any unexpected pairings or groupings of species that suggest a closer evolutionary relationship than previously thought? How could this reshape our understanding of these species' evolutionary paths?\n",
    "\n",
    "3. **Methodology Insights**: Considering the discrepancies between the trees generated by different methods, what might this tell us about the limitations and strengths of each phylogenetic analysis method?\n",
    "\n",
    "4. **Conservation Implications**: Considering the evolutionary relationships revealed in your phylogenetic analysis, what insights can be gained for conservation strategies? Specifically, how could understanding the close evolutionary ties between species, which might be facing distinct environmental challenges, guide targeted conservation efforts?\n",
    "\n",
    "<blockquote style=\"font-family:Arial; color:red; font-size:16px; border-left:0px solid red; padding: 10px;\">\n",
    "    <strong>Don't forget to answer these questions!</strong>\n",
    "</blockquote>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
